{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# cr： /lstm-model-of-stockdata/\n## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-20T08:39:15.437129Z","iopub.execute_input":"2021-06-20T08:39:15.437482Z","iopub.status.idle":"2021-06-20T08:39:15.456486Z","shell.execute_reply.started":"2021-06-20T08:39:15.437361Z","shell.execute_reply":"2021-06-20T08:39:15.454819Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/water3/cleaned_train.csv\n/kaggle/input/water3/cleaned_tests.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport statsmodels.tsa.seasonal as smt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport datetime as dt\nfrom sklearn import linear_model \nfrom sklearn.metrics import mean_absolute_error\nimport plotly\n\n# import the relevant Keras modules\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nfrom datetime import datetime \n\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T08:53:21.731098Z","iopub.execute_input":"2021-06-20T08:53:21.731493Z","iopub.status.idle":"2021-06-20T08:53:21.737555Z","shell.execute_reply.started":"2021-06-20T08:53:21.731456Z","shell.execute_reply":"2021-06-20T08:53:21.736438Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/water3/cleaned_train.csv')\ntests = pd.read_csv('../input/water3/cleaned_tests.csv')\ncols = ['year', 'month', 'date']\ntrain['ymd'] = train[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\ntrain['ymd'] = pd.to_datetime(train['ymd'])\ntrain.info()\ntests['ymd'] = tests[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\ntests['ymd'] = pd.to_datetime(tests['ymd'])\ndf = train.drop(['sub','div','log'],axis = 1)\nwindow_len = 7\n\n#Create a data point (i.e. a date) which splits the training and testing set\nsplit_date = list(df[\"ymd\"][-(10*window_len+1):])[0]\n\n#Split the training and test set\ntraining_set, test_set = df[df['ymd'] < split_date], df[df['ymd'] >= split_date]","metadata":{"execution":{"iopub.status.busy":"2021-06-20T08:56:08.967395Z","iopub.execute_input":"2021-06-20T08:56:08.968002Z","iopub.status.idle":"2021-06-20T08:56:09.018771Z","shell.execute_reply.started":"2021-06-20T08:56:08.967958Z","shell.execute_reply":"2021-06-20T08:56:09.017977Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1032 entries, 0 to 1031\nData columns (total 16 columns):\n #   Column  Non-Null Count  Dtype         \n---  ------  --------------  -----         \n 0   a_fc    1032 non-null   float64       \n 1   b_fc    1032 non-null   float64       \n 2   year    1032 non-null   int64         \n 3   month   1032 non-null   int64         \n 4   date    1032 non-null   int64         \n 5   sum     1032 non-null   float64       \n 6   sub     1032 non-null   float64       \n 7   div     1032 non-null   float64       \n 8   log     1032 non-null   float64       \n 9   sub_1a  1032 non-null   float64       \n 10  sub_1b  1032 non-null   float64       \n 11  sub_2a  1032 non-null   float64       \n 12  sub_2b  1032 non-null   float64       \n 13  sub_3a  1032 non-null   float64       \n 14  sub_3b  1032 non-null   float64       \n 15  ymd     1032 non-null   datetime64[ns]\ndtypes: datetime64[ns](1), float64(12), int64(3)\nmemory usage: 129.1 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"training_set = training_set.drop(['ymd'], 1)\ntest_set = test_set.drop(['ymd'], 1)\n\ntests_set = tests.drop(['sub','div','log'],axis = 1)\ntests_set = tests_set.drop(['ymd'], 1)\ntests_set = tests_set.rename(columns = {'A厂':'a_fc','B厂':'b_fc'})","metadata":{"execution":{"iopub.status.busy":"2021-06-20T08:56:10.028442Z","iopub.execute_input":"2021-06-20T08:56:10.029062Z","iopub.status.idle":"2021-06-20T08:56:10.038388Z","shell.execute_reply.started":"2021-06-20T08:56:10.029014Z","shell.execute_reply":"2021-06-20T08:56:10.037558Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# 1st part predict pseudo out","metadata":{}},{"cell_type":"code","source":"training_set_1 = training_set.drop(['a_fc','b_fc'], axis = 1)\ntest_set_1 = test_set.drop(['a_fc','b_fc'], axis = 1)\ntests_set_1 = tests_set.drop(['a_fc','b_fc'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:03:18.886897Z","iopub.execute_input":"2021-06-20T09:03:18.887293Z","iopub.status.idle":"2021-06-20T09:03:18.895641Z","shell.execute_reply.started":"2021-06-20T09:03:18.887254Z","shell.execute_reply":"2021-06-20T09:03:18.894590Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"training_set_1.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T09:03:31.665268Z","iopub.execute_input":"2021-06-20T09:03:31.665669Z","iopub.status.idle":"2021-06-20T09:03:31.681374Z","shell.execute_reply.started":"2021-06-20T09:03:31.665637Z","shell.execute_reply":"2021-06-20T09:03:31.680302Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"   year  month  date       sum   sub_1a   sub_1b   sub_2a   sub_2b   sub_3a  \\\n0  2018      1     1  390182.0  17673.0  21657.0  23809.0  28277.0  15739.0   \n1  2018      1     2  429512.0   6136.0   6620.0  -1934.0   1489.0 -17918.0   \n2  2018      1     3  442268.0  -8070.0  -5131.0 -24054.0  -8340.0 -26665.0   \n\n    sub_3b  \n0  23146.0  \n1  -1720.0  \n2 -31540.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>date</th>\n      <th>sum</th>\n      <th>sub_1a</th>\n      <th>sub_1b</th>\n      <th>sub_2a</th>\n      <th>sub_2b</th>\n      <th>sub_3a</th>\n      <th>sub_3b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018</td>\n      <td>1</td>\n      <td>1</td>\n      <td>390182.0</td>\n      <td>17673.0</td>\n      <td>21657.0</td>\n      <td>23809.0</td>\n      <td>28277.0</td>\n      <td>15739.0</td>\n      <td>23146.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018</td>\n      <td>1</td>\n      <td>2</td>\n      <td>429512.0</td>\n      <td>6136.0</td>\n      <td>6620.0</td>\n      <td>-1934.0</td>\n      <td>1489.0</td>\n      <td>-17918.0</td>\n      <td>-1720.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018</td>\n      <td>1</td>\n      <td>3</td>\n      <td>442268.0</td>\n      <td>-8070.0</td>\n      <td>-5131.0</td>\n      <td>-24054.0</td>\n      <td>-8340.0</td>\n      <td>-26665.0</td>\n      <td>-31540.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Create windows for training\nLSTM_training_inputs = []\nfor i in range(len(training_set)-window_len):\n    temp_set = training_set[i:(i+window_len)].copy()\n    for col in list(temp_set):\n        temp_set[col] = temp_set[col]/temp_set[col].iloc[0] - 1\n    LSTM_training_inputs.append(temp_set)\n    \n\nLSTM_training_outputs1 = (training_set['sum'][window_len:].values/training_set['sum'][:-window_len].values)-1\nLSTM_training_outputs2 = (training_set['sub_1a'][window_len:].values/training_set['sub_1a'][:-window_len].values)-1\nLSTM_training_outputs3 = (training_set['sub_1b'][window_len:].values/training_set['sub_1b'][:-window_len].values)-1\nLSTM_training_outputs4 = (training_set['sub_2a'][window_len:].values/training_set['sub_2a'][:-window_len].values)-1\nLSTM_training_outputs5 = (training_set['sub_2b'][window_len:].values/training_set['sub_2b'][:-window_len].values)-1\nLSTM_training_outputs6 = (training_set['sub_3a'][window_len:].values/training_set['sub_3a'][:-window_len].values)-1\nLSTM_training_outputs7 = (training_set['sub_3b'][window_len:].values/training_set['sub_3b'][:-window_len].values)-1\n\nLSTM_training_inputs = [np.array(LSTM_training_input) for LSTM_training_input in LSTM_training_inputs]\nLSTM_training_inputs = np.array(LSTM_training_inputs)\n\n#Create windows for testing\nLSTM_test_inputs = []\nfor i in range(len(test_set)-window_len):\n    temp_set = test_set[i:(i+window_len)].copy()\n    for col in list(temp_set):\n        temp_set[col] = temp_set[col]/temp_set[col].iloc[0] - 1\n    LSTM_test_inputs.append(temp_set)\n    \n\nLSTM_test_outputs1 = (test_set['a_fc'][window_len:].values/test_set['a_fc'][:-window_len].values)-1\nLSTM_test_outputs2 = (test_set['b_fc'][window_len:].values/test_set['b_fc'][:-window_len].values)-1\n\nLSTM_test_inputs = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs]\nLSTM_test_inputs = np.array(LSTM_test_inputs)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T08:56:10.918987Z","iopub.execute_input":"2021-06-20T08:56:10.919581Z","iopub.status.idle":"2021-06-20T08:56:16.433964Z","shell.execute_reply.started":"2021-06-20T08:56:10.919528Z","shell.execute_reply":"2021-06-20T08:56:16.433189Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# LSTM_training_outputs1\n# LSTM_training_inputs.shape\nLSTM_test_inputs.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-20T08:56:16.435451Z","iopub.execute_input":"2021-06-20T08:56:16.436019Z","iopub.status.idle":"2021-06-20T08:56:16.441662Z","shell.execute_reply.started":"2021-06-20T08:56:16.435974Z","shell.execute_reply":"2021-06-20T08:56:16.440638Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(64, 7, 12)"},"metadata":{}}]},{"cell_type":"markdown","source":"# undone following part\n6.11","metadata":{}},{"cell_type":"code","source":"#Create windows for testing\nLSTM_tests_inputs = []\nfor i in range(len(tests_set)-window_len):\n    temp_set = tests_set[i:(i+window_len)].copy()\n    for col in list(temp_set):\n        temp_set[col] = temp_set[col]/temp_set[col].iloc[0] - 1\n    LSTM_tests_inputs.append(temp_set)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-06-20T08:57:30.982931Z","iopub.execute_input":"2021-06-20T08:57:30.983493Z","iopub.status.idle":"2021-06-20T08:57:31.899774Z","shell.execute_reply.started":"2021-06-20T08:57:30.983454Z","shell.execute_reply":"2021-06-20T08:57:31.898710Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"LSTM_tests_outputs1 = (tests_set['a_fc'][window_len:].values/tests_set['a_fc'][:-window_len].values)-1\nLSTM_tests_outputs2 = (tests_set['b_fc'][window_len:].values/tests_set['b_fc'][:-window_len].values)-1\n\nLSTM_tests_inputs = [np.array(LSTM_tests_inputs) for LSTM_tests_inputs in LSTM_tests_inputs]\nLSTM_tests_inputs = np.array(LSTM_tests_inputs)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T08:59:40.147502Z","iopub.execute_input":"2021-06-20T08:59:40.147902Z","iopub.status.idle":"2021-06-20T08:59:40.194737Z","shell.execute_reply.started":"2021-06-20T08:59:40.147865Z","shell.execute_reply":"2021-06-20T08:59:40.193646Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"LSTM_training_outputs = pd.DataFrame({'col1': LSTM_training_outputs1,'col2':LSTM_training_outputs2})\nLSTM_test_outputs = pd.DataFrame({'col1': LSTM_test_outputs1,'col2':LSTM_test_outputs2})","metadata":{"execution":{"iopub.status.busy":"2021-06-11T09:05:21.42234Z","iopub.execute_input":"2021-06-11T09:05:21.422691Z","iopub.status.idle":"2021-06-11T09:05:21.430949Z","shell.execute_reply.started":"2021-06-11T09:05:21.422661Z","shell.execute_reply":"2021-06-11T09:05:21.429605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n---\nmodel","metadata":{}},{"cell_type":"code","source":"def build_model(inputs, output_size, neurons, activ_func=\"linear\",\n                dropout=0.10, loss=\"mae\", optimizer=\"adam\"):\n    \n    model = Sequential()\n\n    model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n    model.add(Dropout(dropout))\n    model.add(Dense(units=output_size))\n    model.add(Activation(activ_func))\n\n    model.compile(loss=loss, optimizer=optimizer)\n    return model\n\n\n# bdp入湖开发培训\n# jiangyuqing@sfmail.sf-express.com\n# elenore@sfmail.sf-express.com\n\n# initialise model architecture\nnn_model = build_model(LSTM_training_inputs, output_size=2, neurons = 328)\n# model output is next price normalised to 10th previous closing price\n# train model on data\n# note: eth_history contains information on the training error per epoch\nnn_history = nn_model.fit(LSTM_training_inputs, LSTM_training_outputs, \n                            epochs=25, batch_size=10, verbose=2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T09:07:54.66346Z","iopub.execute_input":"2021-06-11T09:07:54.663884Z","iopub.status.idle":"2021-06-11T09:08:49.593489Z","shell.execute_reply.started":"2021-06-11T09:07:54.663848Z","shell.execute_reply":"2021-06-11T09:08:49.592598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAE = mean_absolute_error(LSTM_test_outputs, nn_model.predict(LSTM_test_inputs))\nprint('The Mean Absolute Error is: {}'.format(MAE))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T09:09:01.101005Z","iopub.execute_input":"2021-06-11T09:09:01.101399Z","iopub.status.idle":"2021-06-11T09:09:01.512725Z","shell.execute_reply.started":"2021-06-11T09:09:01.101361Z","shell.execute_reply":"2021-06-11T09:09:01.511599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ad hoc model, simply predict with time;. ","metadata":{}},{"cell_type":"code","source":"train = train[['year','month','date','ymd']]\ntests = tests[['year','month','date','ymd']]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T09:16:34.07973Z","iopub.execute_input":"2021-06-11T09:16:34.080161Z","iopub.status.idle":"2021-06-11T09:16:34.087774Z","shell.execute_reply.started":"2021-06-11T09:16:34.080116Z","shell.execute_reply":"2021-06-11T09:16:34.086474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LSTM_training_outputs","metadata":{"execution":{"iopub.status.busy":"2021-06-11T09:18:11.952071Z","iopub.execute_input":"2021-06-11T09:18:11.952455Z","iopub.status.idle":"2021-06-11T09:18:11.964953Z","shell.execute_reply.started":"2021-06-11T09:18:11.952424Z","shell.execute_reply":"2021-06-11T09:18:11.963935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# initialise model architecture\nnn_model = build_model(LSTM_training_inputs, output_size=2, neurons = 328)\n# model output is next price normalised to 10th previous closing price\n# train model on data\n# note: eth_history contains information on the training error per epoch\nnn_history = nn_model.fit(LSTM_training_inputs, LSTM_training_outputs, \n                            epochs=25, batch_size=10, verbose=2, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]}]}